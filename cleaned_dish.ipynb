{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8440b-1d58-437a-a5db-2e7d4df77cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bdccc-46ea-43c5-9525-b22d9c39cfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4544eb05-405c-4874-8a90-8c7bb0de31a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "with open(r\"C:\\Users\\DELL\\Downloads\\dish_names.json\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Function to clean a list of ingredients\n",
    "def clean_ingredient_list(ingredient_list):\n",
    "    cleaned = []\n",
    "    for ingredient in ingredient_list:\n",
    "        cleaned_ing = re.sub(r'\\([^)]*\\)', '', ingredient)  # remove text inside brackets\n",
    "        cleaned_ing = re.sub(r'\\b\\d+[%]?\\b', '', cleaned_ing)  # remove percentages and digits\n",
    "        cleaned_ing = re.sub(\n",
    "            r'\\b\\d+\\s?(oz|lb|g|ml|cup|cups|tablespoons|tbsp|teaspoons|tsp|pkg|can|cans|pound|pounds)\\b',\n",
    "            '', cleaned_ing, flags=re.IGNORECASE)\n",
    "        cleaned_ing = re.sub(r'[^a-zA-Z\\s]', '', cleaned_ing)  # remove special characters\n",
    "        cleaned_ing = cleaned_ing.strip().lower()\n",
    "        if cleaned_ing:\n",
    "            cleaned.append(cleaned_ing)\n",
    "    return cleaned\n",
    "\n",
    "# Apply cleaning to all entries\n",
    "for entry in data:\n",
    "    entry[\"cleaned_ingredients\"] = clean_ingredient_list(entry.get(\"ingredients\", []))\n",
    "\n",
    "# Save cleaned data if needed\n",
    "with open(\"cleaned_dishes.json\", \"w\") as outfile:\n",
    "    json.dump(data, outfile, indent=2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbbff640-2110-4149-a6c4-09c3b9eb4544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dish: Greek Salad\n",
      "Cleaned Ingredients: ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']\n",
      "Dish: Southern_Us Special\n",
      "Cleaned Ingredients: ['plain flour', 'ground pepper', 'salt', 'tomatoes', 'ground black pepper', 'thyme', 'eggs', 'green tomatoes', 'yellow corn meal', 'milk', 'vegetable oil']\n",
      "Dish: Filipino Special\n",
      "Cleaned Ingredients: ['eggs', 'pepper', 'salt', 'mayonaise', 'cooking oil', 'green chilies', 'grilled chicken breasts', 'garlic powder', 'yellow onion', 'soy sauce', 'butter', 'chicken livers']\n"
     ]
    }
   ],
   "source": [
    "# Optional: print first 3 cleaned samples\n",
    "for entry in data[:3]:\n",
    "    print(\"Dish:\", entry[\"dish_name\"])\n",
    "    print(\"Cleaned Ingredients:\", entry[\"cleaned_ingredients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02f7527-cea5-4c79-8f29-2d227e296866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare data for model\n",
    "dishes = []\n",
    "ingredients_corpus = []\n",
    "\n",
    "for entry in data:\n",
    "    if entry[\"cleaned_ingredients\"]:\n",
    "        ingredients_text = \" \".join(entry[\"cleaned_ingredients\"])\n",
    "        ingredients_corpus.append(ingredients_text)\n",
    "        dishes.append(entry[\"dish_name\"])\n",
    "\n",
    "# Convert ingredients to feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(ingredients_corpus)\n",
    "y = dishes\n",
    "\n",
    "# Split data (optional - for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict function\n",
    "def predict_dish(input_ingredients):\n",
    "    cleaned_input = clean_ingredient_list(input_ingredients)\n",
    "    input_text = \" \".join(cleaned_input)\n",
    "    input_vector = vectorizer.transform([input_text])\n",
    "    prediction = knn.predict(input_vector)\n",
    "    return prediction[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86da9008-831f-48ac-a0c5-9a3175e84e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Dish: Italian Special\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "user_input = [\"garlic\", \"lemon juice\", \"romaine lettuce\", \"black olives\", \"olive oil\", \"feta cheese\"]\n",
    "predicted_dish = predict_dish(user_input)\n",
    "print(\"Predicted Dish:\", predicted_dish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca22e50-cdd6-4011-bdd3-d30187ec44c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to JSON file in the same directory\n",
    "with open(\"cleaned_dishes.json\", \"w\") as outfile:\n",
    "    json.dump(data, outfile, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151fab3e-34ef-41b5-a7d5-6397e34f4654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
